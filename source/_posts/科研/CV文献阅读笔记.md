# 文献阅读笔记

## Self-supervised Learning of Adversarial Example- Towards Good Generalizations for Deepfake Detection, CVPR 2022

**自监督学习对抗的例子：Deepfake检测的良好推广**

> 代码：https://github.com/liangchen527/SLADD.

### 是什么

这篇论文探讨了一种自我监督学习方法，用于生成对抗样本，以提高深度学习模型在检测Deepfake（深度伪造）方面的泛化能力。通过在训练过程中生成对抗样本，该方法可以使模型更好地学习到真实和虚假图像之间的差异，并提高其在未见过的数据上的性能。

### 为什么

这篇论文的主要目的是提高深度学习模型在检测Deepfake（深度伪造）方面的泛化能力。传统的监督学习方法需要大量标注的数据，但是在Deepfake检测任务中，由于Deepfake技术的不断进步，标注数据很难跟上Deepfake技术的发展。因此，自监督学习方法成为一种可行的解决方案，可以利用未标注数据来提高模型的性能。同时，对抗样本也是一种常见的攻击手段，可以欺骗深度学习模型的预测结果。因此，本文提出了一种自监督学习方法，用于生成对抗样本，以提高深度学习模型在检测Deepfake方面的鲁棒性和泛化能力。

### 怎么做

这篇论文提出了一种自监督学习方法，用于生成对抗样本，以提高深度学习模型在检测Deepfake方面的鲁棒性和泛化能力。具体来说，该方法由两个阶段组成：

1. 自监督学习阶段：利用大量未标注的数据，训练一个自监督学习模型，用于生成对抗样本。该模型通过最大化输入图像和对抗样本之间的相似度来学习图像的表示，从而可以生成更具有欺骗性的对抗样本。
2. 混合样本训练阶段：利用Mixup方法生成大量的混合样本，用于训练深度学习模型。Mixup方法通过线性插值的方式生成混合样本和混合标签，从而可以增强模型的鲁棒性和泛化能力。

通过这两个阶段的训练，该方法可以提高深度学习模型在检测Deepfake方面的泛化能力和对抗攻击的鲁棒性。

![模型整体架构](C:/Users/jiang/AppData/Roaming/Typora/typora-user-images/image-20230714215204315.png)

## Protecting Celebrities from DeepFake with Identity Consistency Transformer, CVPR 2022

### 目的

### 方法概述

### 核心实验结果

### 主要创新点

### 论文的不足

## 论文题目

### 目的

### 方法概述

### 核心实验结果

### 主要创新点

### 论文的不足