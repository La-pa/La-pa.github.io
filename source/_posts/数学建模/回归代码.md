---
title: 回归代码
tags: [数学建模, 机器学习, 数据处理]
categories: 数学建模
date: 2023-03-01 19:20:00
---
## 线性回归
### 正规方程
##### 注意

1. 当采用普通的线性回归的时候，是无需标准化的。因为标准化前后，不会影响线性回归预测值。
2. 适合小数据规模，不能解决过拟合的问题

##### 代码
```python
from sklearn.linear_model import LinearRegression

estimator = LinearRegression()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
##### 属性
```python
# 回归系数
estimator.coef_

# 
estimator.intercept_
```

### 梯度下降法
##### 注意

1. SGDRegressor类实现了随机梯度下降学习，它支持不同的Ioss函数和正则化惩罚项来拟合线性回归模型。
2. 适合大规模数据
##### 代码
```python
from sklearn.linear_model import SGDRegressor

estimator = SGDRegressor()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
##### 参数
```python
# 损失函数
	#普通最小二乘法
loss=”squared_loss”

# 惩罚力度
penalty="l2"
	# L2正则化

# 学习率（梯度下降强度）
```
##### 属性
```python
# 回归系数
estimator.coef_

# 偏置
estimator.intercept_
```
### 岭回归
#### 注意

#### 代码
```python
from sklearn.linear_model import Ridge

estimator = Ridge()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
#### 参数
```python
# alpha:正则化力度，取值0~1，1~10
alpha = 1

# solver:会根据数据自动选择优化方法 
	# sag:如果数据集、特征都比较大，选择该随机梯度下降优化

# normalize:数据是否进行标准化 normalize:=False:
	# 可以在fit之前调用preprocessing.StandardScaler标准化数据
```
#### 属性
```python
# 回归系数
estimator.coef_

# 偏置
estimator.intercept_
```
### Lasso回归
#### 注意

1. 模型现状：目前Lasso回归的使用率远高于岭回归，因此实际建模时推荐优先使用Lasso回归。
2. Lasso回归的最大优点：能够把不重要的自变量的回归系数压缩到零，从而起到很好的变量筛选作用。
3. Lasso回归的缺点：没有显式解，只能使用近似估计算法计算回归系数。
4. 什么情况下进行Lasso回归：首先对原始模型进行多重共线性检验，如果存在多重共线性，那么就可以用Lasso回归进行自变量筛选并回归。

#### 代码
```python
from sklearn.linear_model import Lasso

estimator = Lasso()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
#### 参数
```python
alpha=1.0, 
fit_intercept=True, 
normalize=False,
precompute=False,
copy_X=True,
max_iter=1000,
tol=1e-4, 
warm_start=False,
positive=False,
random_state=None,
selection='cyclic'

```
#### 属性
```python
# 回归系数
estimator.coef_

# 偏置
estimator.intercept_
```
### 
## 决策树
#### 代码
```python
from sklearn.tree import DecisionTreeRegressor

estimator = DecisionTreeRegressor()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
## 集成学习
### 随机森林
#### 代码
```python
from sklearn.ensemble import RandomForestRegressor

estimator = RandomForestRegressor(random_state=15)
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
### AdaBoost
#### 代码
```python
from sklearn.ensemble import AdaBoostRegressor

estimator = AdaBoostRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
### ExtraTrees
#### 代码
```python
from sklearn.ensemble import ExtraTreesRegressor

estimator =  ExtraTreesRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
### GBDT
#### 代码
```python
from sklearn.ensemble import GradientBoostingRegressor

estimator = GradientBoostingRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
## 支持向量机
### SVR
#### 代码
```python
from sklearn.svm import SVR

estimator = SVR()
estimator.fit(X_train, y_train)
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
## 基于 GBDT框架的算法
### XGBoost
#### 代码
```python
from xgboost import XGBRegressor

estimator = XGBRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
### LightGBM
#### 代码
```python
from lightgbm import LGBMRegressor

estimator = LGBMRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
### CatBoost
#### 代码
```python
from catboost import CatBoostRegressor

estimator =  CatBoostRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```
## BP神经网络
#### 代码
```python
from sklearn.neural_network import MLPRegressor

estimator = MLPRegressor()
estimator.fit(X_train, y_train)  
y_predict = estimator.predict(X_test)
print("Train set score: ", estimator.score(X_train, y_train))
print("Test set score: ", estimator.score(X_test, y_test))
```

1. $27 \leq \sum_{i=1}^{n} x_i \leq 33$

 2. $x_i \geq 2.5$