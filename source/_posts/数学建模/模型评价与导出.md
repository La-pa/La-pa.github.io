---
title: 模型评价与导出
tags: [数学建模, 机器学习, 数据处理]
categories: 数学建模
date: 2023-03-01 19:20:00
---
## 模型评价
### 回归
#### MSE(平均平方误差、均方误差)
![](https://cdn.nlark.com/yuque/__latex/b3b54b42194bc3e5855c00856a4b5425.svg#card=math&code=M%20S%20E%3D%5C%20%7B%5Cfrac%7B1%7D%7Bm%7D%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28f_%7Bi%7D-y_%7Bi%7D%29%5E%7B2%7D&id=DwTmm)
```python
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_test,y_predict))
```
#### RMSE(均方根误差、标准误差）
![](https://cdn.nlark.com/yuque/__latex/1f72ee19c67a17243bb29ce5cb3cea56.svg#card=math&code=R%20M%20S%20E%3D%5Csqrt%7B%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28f_i-y_%7Bi%7D%29%5E%7B2%7D%7D&id=zMFK6)
```python
import numpy as np
from sklearn.metrics import mean_squared_error
print(np.sqrt(mean_squared_error(y_test,y_predict)))
```
#### MAE(平均绝对误差）
![](https://cdn.nlark.com/yuque/__latex/b866064ddf5ed8c0c9916558c9b32d1e.svg#card=math&code=%0AM%20A%20E%3D%7B%5Cfrac%7B1%7D%7Bm%7D%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7Cf_%7Bi%7D-y_%7Bi%7D%7C&id=olhF7)
```python
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_test,y_predict))
```
#### R2_score
R Squared又叫可决系数(coefficient of determination)也叫拟合优度,反映的是自变量x对因变量y的变动的解释的程度.越接近于1,说明模型拟合得越好.
![](https://cdn.nlark.com/yuque/__latex/2abfe1c20f83fd845ea69b79430c2646.svg#card=math&code=R%5E%7B2%7D%3D1-%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28f_%7Bi%7D-y_%7Bi%7D%29%5E%7Bz%7D%7D%7B%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28%5Coverline%7B%7By_%7Bi%7D%7D%7D-y_%7Bi%7D%29%5E%7Bz%7D%7D&id=lswUN)
```python
from sklearn.metrics import r2_score
print(r2_score(y_test,y_predict))
```
### 分类
#### 基本概念
针对一个二分类问题，即将实例分成正类（positive）或负类（negative），在实际分类中会出现以下四种情况：

1. 若一个实例是正类，并且被预测为正类，即为真正类(True Positive TP)
2. 若一个实例是正类，但是被预测为负类，即为假负类(False Negative FN)
3. 若一个实例是负类，但是被预测为正类，即为假正类(False Positive FP)
4. 若一个实例是负类，并且被预测为负类，即为真负类(True Negative TN)
#### 准确率
定义：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。
![](https://cdn.nlark.com/yuque/__latex/3f3e5c08c246d343b93701f36792d0c0.svg#card=math&code=A%20c%20c%20u%20r%20a%20c%20y%3D%7B%5Cfrac%7BT%20P%2BT%20N%7D%7BT%20P%2BT%20N%2BF%20P%2BF%20N%7D%7D&id=eYC4l)
缺点：在正负样本不平衡的情况下，这个指标有很大的缺陷。例如：给定一组测试样本共1100个实例，其中1000个是负类，剩余100个是正类。即使分类模型将所有实例均预测为负类，Accuracy也有90%以上，这样就没什么意义了。

#### 精确率(Precision)
定义：精确率是检索出相关文档数与检索出的文档总数的比率（正确分类的正例个数占分类为正例的实例个数的比例），衡量的是检索系统的查准率。
![](https://cdn.nlark.com/yuque/__latex/b8b657c8e560bf68413139017bcc5326.svg#card=math&code=p%20r%20e%20c%20i%20s%20i%20o%20n%3D%7B%5Cfrac%7BT%20P%7D%7BT%20P%2BF%20P%7D%7D&id=ySZZ3)
#### 召回率(Recall)
召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率（正确分类的正例个数占实际正例个数的比例），衡量的是检索系统的查全率。
![](https://cdn.nlark.com/yuque/__latex/c3a69d37ecc735a42e1123ccf4614a55.svg#card=math&code=%0Ar%20e%20c%20a%20l%20l%3D%7B%5Cfrac%7BT%20P%7D%7BT%20P%2BF%20N%7D%7D&id=sMOIx)
#### F1-score
为了能够评价不同算法优劣，在Precision和Recall的基础上提出了F1值的概念，来对Precision和Recall进行整体评价，用于反应模型的健壮性。F1的定义如下：
![](https://cdn.nlark.com/yuque/__latex/c4be78c70bd1e25002c3b32eba49cf43.svg#card=math&code=F1%3D%20%5Cfrac%7Bprecision%2A%20recall%2A2%7D%7Bprecision%20%2B%20recall%7D&id=uU0j2)
#### 计算指标的代码
```python
from sklearn.metrics import classification_report

report = classification_report(y_test, y_predict, labels=[0,1,2], 
                               target_names=['setosa', 'versicolor', 'virginica'])
print(report)
```
#### ROC和AUC
![](https://cdn.nlark.com/yuque/0/2023/png/29247769/1677935854334-5c85702f-23fe-4052-b590-d238f7c712dd.png#averageHue=%23f9f9f9&from=url&id=o16Bg&originHeight=992&originWidth=986&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&status=done&style=none&title=)
![](https://cdn.nlark.com/yuque/0/2023/png/29247769/1677935878158-48e6fd73-46da-4919-bd3d-b3423b58f88c.png#averageHue=%23f1f1f1&from=url&id=CbL2b&originHeight=484&originWidth=1005&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&status=done&style=none&title=)
#### 计算AUC
```python
from sklearn.metrics import roc_auc_score

# 计算AUC指标
if len(np.unique(y_test)) == 2:
    # 二分类问题
    auc = roc_auc_score(y_test, y_predict)
else:
    # 多分类问题，使用“一对多”策略
    auc = roc_auc_score(y_test, estimator.predict_proba(X_test), multi_class='ovr')

# 输出AUC值
print('AUC score:', auc)
```
### ROC曲线可视化
```python
# 预测测试集中每个样本的概率
y_score = estimator.predict_proba(X_test)

# 将每个类别的概率转换为二元标签
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
n_classes = y_test_bin.shape[1]

# 计算每个类别的ROC曲线和AUC指标
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# 计算平均ROC曲线和AUC指标
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# 绘制每个类别的ROC曲线
plt.figure()
lw = 2
colors = ['blue', 'red', 'green']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=lw,
             label='ROC curve of class {0} (AUC = {1:0.2f})'
             ''.format(i, roc_auc[i]))

# 绘制平均ROC曲线
plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average ROC curve (AUC = {0:0.2f})'
         ''.format(roc_auc["micro"]),
         color='deeppink', linestyle=':', linewidth=4)

# 添加其他图形元素
plt.plot([0, 1], [0, 1], 'k--', lw=lw)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve for multi-class classification')
plt.legend(loc="lower right")
plt.show()

```
## 模型导出
### 模型导出
```python
import joblib

joblib.dump(estimator, "*.pkl")
```
### 模型导入
```python
import joblib

estimator= joblib.load("*.pkl")
```
## 模型调整
### 网格搜索
```python
param_dict = {
    "max_depth": range(1,10),
    "n_estimators":range(100,1000,200)
}

from sklearn.model_selection import GridSearchCV
grid_search = GridSearchCV(estimator, param_grid=param_dict, cv=10)

grid_search.fit(X_train, y_train)

# 模型最好参数
grid_search.best_params_
# 模型最好评分
grid_search.best_score_
# 最好模型的实例对象
grid_search.best_estimator_
# 交叉验证的结果
grid_search.cv_results_
```
### 随机网格搜索
```python
param_dict = {
    "max_depth": range(1,10),
    "n_estimators":range(100,1000,200)
}
#RandomizedSearchCV参数说明，estimator设置训练的学习器
#param_dist字典类型，放入参数搜索范围
#scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“
#n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长
#n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU
grid = RandomizedSearchCV(estimator,param_dist,cv = 5,scoring = 'neg_log_loss',n_iter=300,n_jobs = -1)

```

### k折交叉验证
```python
from sklearn.model_selection import cross_val_score

cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, 
                cv=None, n_jobs=None, verbose=0, fit_params=None, 
                pre_dispatch="2*n_jobs", error_score=np.nan)

# estimator：估计器，也就是模型
# X, y：数据，标签值
# soring：调用的方法
# cv：交叉验证生成器或可迭代的次数
# n_jobs：同时工作的cpu个数（-1代表全部）
# verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，>1：对每个子模型都输出
# fit_params：传递给估计器的拟合方法的参数
# pre_dispatch：控制并行执行期间调度的作业数量。减少这个数量对于避免在CPU发送更多作业时CPU内存消耗的扩大是有用的。

```
## 数据的导入与导出
### 数据导入

### 数据导出
#### CSV
```python
import pandas as pd

target = pd.DataFrame(data=y_predict, columns=["y_pred"])
target.to_csv("test.csv", index=False)
```
**参数**
```python
另外还可以使用sep参数指定分隔符，columns传入一个序列指定列名，编码用encoding传入。
如果不需要表头，可以将header设为False。
如果文件较大，可以使用compression进行压缩：

# 创建一个包含out.csv的压缩文件out.zip
compression_opts = dict(method='zip', archive_name='out.csv')
df.to_csv('out.zip', index=False, compression=compression_opts)

```

#### Excel
```python
 # 导出，可以指定文件路径
df.to_excel('path_to_file.xlsx')
# 指定Sheet名，不要索引
df.to_excel('path_to_file.xlsx', sheet_name='Sheet1', index=False) 
# 指定索引名，不合并单元格 
df.to_excel('path_to_file.xlsx', index_label='label', merge_cell=False) 
# 将多个df分不同sheet导入到一个Excel文件中
with pd.ExcelWriter('path_to_file.xlsx') as writer:
	df1.to_excel(writer, sheet_name='Sheet1')
	df2.to_excel(writer, sheet_name='Sheet2')

```
